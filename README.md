# FasterDNN
Deep Neural Networks(include DNN/CNN/RNN) run on mobile devices

* step1: Compression/Pruning parameters
* step2: Speed up `matrix * matrix` or `matrix * vector`


## Compression/Pruning
* [Learning both Weights and Connections for Efficient Neural Networks](http://arxiv.org/abs/1506.02626)
* [Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding](http://arxiv.org/abs/1510.00149)


## Speed Up


